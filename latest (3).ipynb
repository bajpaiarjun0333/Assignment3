{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom torch import optim\nimport torch.nn.functional as F\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nimport random\nfrom datetime import datetime\nimport pandas\nimport wandb","metadata":{"_uuid":"7d6725f5-8201-40d3-9ba7-bed984babfa2","_cell_guid":"b9eb7e48-dae2-4f03-82cb-213ba1c76462","collapsed":false,"execution":{"iopub.status.busy":"2023-05-20T15:41:54.763404Z","iopub.execute_input":"2023-05-20T15:41:54.763795Z","iopub.status.idle":"2023-05-20T15:41:54.771987Z","shell.execute_reply.started":"2023-05-20T15:41:54.763763Z","shell.execute_reply":"2023-05-20T15:41:54.769588Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"wandb.login()","metadata":{"_uuid":"f45e74b5-91a1-4dd3-a48a-749a40af5b72","_cell_guid":"621495e6-9578-4285-bdfb-b6020994da3e","collapsed":false,"execution":{"iopub.status.busy":"2023-05-20T15:41:54.907270Z","iopub.execute_input":"2023-05-20T15:41:54.907544Z","iopub.status.idle":"2023-05-20T15:41:54.920276Z","shell.execute_reply.started":"2023-05-20T15:41:54.907520Z","shell.execute_reply":"2023-05-20T15:41:54.919187Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_input=None\ntrain_output=None\nvalid_input=None\nvalid_output=None\ntest_input=None\ntest_output=None","metadata":{"_uuid":"606add92-d1d5-4c76-bf80-8154208d8f37","_cell_guid":"78844bba-4c67-4f00-9789-60172d127f7b","collapsed":false,"execution":{"iopub.status.busy":"2023-05-20T15:41:55.074135Z","iopub.execute_input":"2023-05-20T15:41:55.074455Z","iopub.status.idle":"2023-05-20T15:41:55.079070Z","shell.execute_reply.started":"2023-05-20T15:41:55.074427Z","shell.execute_reply":"2023-05-20T15:41:55.078090Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def loadData():\n    global train_input, train_output, valid_input, valid_output, test_input, test_output\n    data_train = pandas.read_csv('/kaggle/input/aksharantar-sampled/aksharantar_sampled/hin/hin_train.csv', header=None)\n    train_input = data_train.iloc[:,0]\n    train_output = data_train.iloc[:,1]\n    data_valid = pandas.read_csv('/kaggle/input/aksharantar-sampled/aksharantar_sampled/hin/hin_valid.csv', header=None)\n    valid_input = data_valid.iloc[:,0]\n    valid_output = data_valid.iloc[:,1]\n    data_test = pandas.read_csv('/kaggle/input/aksharantar-sampled/aksharantar_sampled/hin/hin_test.csv', header=None)\n    test_input = data_test.iloc[:,0]\n    test_output = data_test.iloc[:,1]\n    max_inp_len=0\n    max_out_len=0\n    for i in train_input:\n        max_inp_len=max(max_inp_len,len(i))\n    for i in train_output:\n        max_out_len=max(max_out_len,len(i))\n    for i in valid_input:\n        max_inp_len=max(max_inp_len,len(i))\n    for i in valid_output:\n        max_out_len=max(max_out_len,len(i))\n    for i in test_input:\n        max_inp_len=max(max_inp_len,len(i))\n    for i in test_output:\n        max_out_len=max(max_out_len,len(i))\n    return max_inp_len+1,max_out_len+1","metadata":{"_uuid":"203fa088-6fd6-44e3-b354-dbe74562d1ba","_cell_guid":"76c06605-4b21-4769-bdad-ef20990c04ff","collapsed":false,"execution":{"iopub.status.busy":"2023-05-20T15:41:55.202464Z","iopub.execute_input":"2023-05-20T15:41:55.203267Z","iopub.status.idle":"2023-05-20T15:41:55.213124Z","shell.execute_reply.started":"2023-05-20T15:41:55.203230Z","shell.execute_reply":"2023-05-20T15:41:55.212195Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"SOW_token = 0\nEOW_token = 1\nPAD_token = 2","metadata":{"_uuid":"82ba4c06-31b6-4b48-a5c2-ffa5ae7cb447","_cell_guid":"4f9c193b-0bc8-4c7c-8d0a-5113951de100","collapsed":false,"execution":{"iopub.status.busy":"2023-05-20T15:41:55.342016Z","iopub.execute_input":"2023-05-20T15:41:55.342534Z","iopub.status.idle":"2023-05-20T15:41:55.347628Z","shell.execute_reply.started":"2023-05-20T15:41:55.342501Z","shell.execute_reply":"2023-05-20T15:41:55.346393Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Dictionary:\n    def __init__(self, max_inp_length):\n        self.index = {}\n        self.char = {0: \"#\", 1: \"$\",2:\"*\"}\n        self.n_chars = 3  # Count SOS and EOS\n        self.max_inp_len=max_inp_len\n        self.max_out_len=max_out_len\n\n    def preprocess(self, w):\n        for x in w:\n            for c in x:\n                if c not in self.index:\n                    self.index[c]=self.n_chars\n                    self.char[self.n_chars]=c\n                    self.n_chars+=1\n                \n    def createBatches(self, words, batch_size):\n        x=[]\n        for w in words:\n            a=[]\n            for i in w:\n                a.append(self.index[i])\n            a.append(EOW_token)\n            #padd here\n            diff=self.max_inp_len-len(a)\n            a.extend([PAD_token]*diff)\n            a_tensor=torch.tensor(a, dtype=torch.long,device=device)\n            x.append(a_tensor)\n        batches=[]\n        size=len(x)\n        for i in range(0,size,batch_size):\n            if i+batch_size>=size:\n                break\n            temp=torch.stack(x[i:i+batch_size]).to(device)\n            batches.append(temp.transpose(0,1))\n        return batches\n    \n    def driver(self, words,batch_size):\n        self.preprocess(words)\n        return self.createBatches(words,batch_size)","metadata":{"_uuid":"19a310fd-736a-4689-a4dd-bfae27d29802","_cell_guid":"6cd86a77-ffb5-45ec-b403-fe88a335fe01","collapsed":false,"execution":{"iopub.status.busy":"2023-05-20T15:41:55.513246Z","iopub.execute_input":"2023-05-20T15:41:55.513525Z","iopub.status.idle":"2023-05-20T15:41:55.525893Z","shell.execute_reply.started":"2023-05-20T15:41:55.513500Z","shell.execute_reply":"2023-05-20T15:41:55.523772Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Encoder(nn.Module):\n    def __init__(self, input_size, params):\n        super(Encoder, self).__init__()\n        self.hs = params[\"hs\"]\n        self.dp = nn.Dropout(params[\"de\"])\n        self.nl = params[\"nl\"]\n        self.bs = params[\"bs\"]\n        self.es = params[\"es\"]\n        self.ct = params[\"ct\"]\n        self.em = nn.Embedding(input_size, params[\"es\"])\n        self.bi = params[\"bi\"]\n        if(params[\"ct\"] == \"GRU\"):\n            self.gru = nn.GRU(params[\"es\"], params[\"hs\"], params[\"nl\"], dropout = params[\"de\"], bidirectional = params[\"bi\"])\n        elif(params[\"ct\"] == \"LSTM\"):\n            self.lstm = nn.LSTM(params[\"es\"], params[\"hs\"], params[\"nl\"], dropout = params[\"de\"], bidirectional = params[\"bi\"])\n        elif(params[\"ct\"] == \"RNN\"):\n            self.rnn = nn.RNN(params[\"es\"], params[\"hs\"], params[\"nl\"], dropout = params[\"de\"], bidirectional = params[\"bi\"])\n\n    def forward(self, input, hidden):\n        output = self.dp(self.em(input).view(-1,self.bs, self.es))\n        \n        if(self.ct == \"RNN\"):\n            _, hidden = self.rnn(output, hidden)\n\n        if(self.ct == \"LSTM\"):\n            _, (hidden, cell) = self.lstm(output)\n            \n        if(self.ct == \"GRU\"):\n            _, hidden = self.gru(output, hidden)\n            \n        if self.bi:\n            hidden = hidden.reshape(2, hidden.size(0)//2, hidden.size(1), hidden.size(2))\n            hidden = torch.add(hidden[0]*0.5, hidden[1]*0.5)\n            \n            if(self.ct == \"LSTM\"):\n                cell = cell.reshape(2, cell.size(0)//2, cell.size(1), cell.size(2))\n                cell = torch.add(cell[0]*0.5, cell[1]*0.5)\n        \n        if self.ct != \"LSTM\":\n            return hidden\n        else:\n            return hidden,cell\n\n    def initHidden(self):\n        if self.bi==False:\n            return torch.zeros(self.nl, self.bs, self.hs, device=device)\n        else:\n            return torch.zeros(2*self.nl, self.bs, self.hs, device=device)","metadata":{"_uuid":"6e4f4728-a65e-4280-930e-f46e49b1ec34","_cell_guid":"0b5b6094-a915-4a75-8cb6-a2eb6ff941c9","collapsed":false,"execution":{"iopub.status.busy":"2023-05-20T15:41:55.662376Z","iopub.execute_input":"2023-05-20T15:41:55.662639Z","iopub.status.idle":"2023-05-20T15:41:55.678095Z","shell.execute_reply.started":"2023-05-20T15:41:55.662615Z","shell.execute_reply":"2023-05-20T15:41:55.677112Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class EncoderAttention(nn.Module):\n    def __init__(self, input_size, params):\n        super(EncoderAttention, self).__init__()\n        self.hs = params[\"hs\"]\n        self.dp = nn.Dropout(params[\"de\"])\n        self.nl = params[\"nl\"]\n        self.bs = params[\"bs\"]\n        self.es = params[\"es\"]\n        self.ct = params[\"ct\"]\n        self.em = nn.Embedding(input_size, params[\"es\"])\n        self.bi = params[\"bi\"]\n        if(params[\"ct\"] == \"GRU\"):\n            self.gru = nn.GRU(params[\"es\"], params[\"hs\"], params[\"nl\"], dropout = params[\"de\"], bidirectional = params[\"bi\"])\n        elif(params[\"ct\"] == \"LSTM\"):\n            self.lstm = nn.LSTM(params[\"es\"], params[\"hs\"], params[\"nl\"], dropout = params[\"de\"], bidirectional = params[\"bi\"])\n        elif(params[\"ct\"] == \"RNN\"):\n            self.rnn = nn.RNN(params[\"es\"], params[\"hs\"], params[\"nl\"], dropout = params[\"de\"], bidirectional = params[\"bi\"])\n\n    def forward(self, input, hidden):\n        output = self.dp(self.em(input).view(-1,self.bs, self.es))\n        \n        if(self.ct == \"RNN\"):\n            output, hidden = self.rnn(output, hidden)\n\n        if(self.ct == \"LSTM\"):\n            output, (hidden, cell) = self.lstm(output)\n            \n        if(self.ct == \"GRU\"):\n            output, hidden = self.gru(output, hidden)\n            \n        if self.bi:\n            hidden = hidden.reshape(2, hidden.size(0)//2, hidden.size(1), hidden.size(2))\n            hidden = torch.add(hidden[0]*0.5, hidden[1]*0.5)\n            \n            if(self.ct == \"LSTM\"):\n                cell = cell.reshape(2, cell.size(0)//2, cell.size(1), cell.size(2))\n                cell = torch.add(cell[0]*0.5, cell[1]*0.5)\n            \n            output = output.permute(2, 1, 0)\n            output = torch.split(output, output.shape[0]//2)\n            output = torch.add(output[0].permute(2, 1, 0)*0.5, output[1].permute(2, 1, 0)*0.5)\n        \n        if self.ct != \"LSTM\":\n            return output,hidden\n        else:\n            return output,hidden,cell\n\n    def initHidden(self):\n        if self.bi==False:\n            return torch.zeros(self.nl, self.bs, self.hs, device=device)\n        else:\n            return torch.zeros(2*self.nl, self.bs, self.hs, device=device)","metadata":{"_uuid":"5e488ffc-9487-4684-9210-99c345d68195","_cell_guid":"431fb6bb-18f4-402b-9c07-50948ee34b36","collapsed":false,"execution":{"iopub.status.busy":"2023-05-20T15:41:55.821357Z","iopub.execute_input":"2023-05-20T15:41:55.821870Z","iopub.status.idle":"2023-05-20T15:41:55.848321Z","shell.execute_reply.started":"2023-05-20T15:41:55.821836Z","shell.execute_reply":"2023-05-20T15:41:55.847255Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Decoder(nn.Module):\n    def __init__(self, params, output_size):\n        super(Decoder, self).__init__()\n        self.hs = params[\"hs\"]\n        self.dp = nn.Dropout(params[\"dd\"])\n        self.nl = params[\"nl\"]\n        self.bs = params[\"bs\"]\n        self.es = params[\"es\"]\n        self.em = nn.Embedding(output_size, params[\"es\"])\n        self.ct = params[\"ct\"]\n        \n        \n        if(params[\"ct\"] == \"LSTM\"):\n            self.lstm = nn.LSTM(params[\"es\"], params[\"hs\"], params[\"nl\"], dropout = params[\"dd\"])\n        \n        if(params[\"ct\"] == \"RNN\"):\n            self.rnn = nn.RNN(params[\"es\"], params[\"hs\"], params[\"nl\"], dropout = params[\"dd\"])\n        \n        if(params[\"ct\"] == \"GRU\"):\n            self.gru = nn.GRU(params[\"es\"], params[\"hs\"], params[\"nl\"], dropout = params[\"dd\"])\n        \n                \n        self.softmax = nn.LogSoftmax(dim=1)\n        \n        self.out = nn.Linear(params[\"hs\"], output_size)\n        \n\n    def forward(self, input, hidden):\n        \n        output = torch.relu(self.dp(self.em(input).view(-1, self.bs, self.es)))\n        \n        if(self.ct == \"RNN\"):\n            output, hidden = self.rnn(output, hidden)\n        \n        if(self.ct == \"LSTM\"):\n            output, (hidden, cell) = self.lstm(output, (hidden[0], hidden[1]))\n        \n        if(self.ct == \"GRU\"):\n            output, hidden = self.gru(output, hidden)\n            \n        if self.ct == \"LSTM\":\n            return self.softmax(self.out(output[0])), hidden, cell\n        \n        return self.softmax(self.out(output[0])), hidden\n\n    def initHidden(self):\n        return torch.zeros(self.nl, self.bs, self.hs, device=device)","metadata":{"_uuid":"978bcb1d-bc79-40c6-b480-ff68f1a8ff11","_cell_guid":"eb9fede1-867e-45cd-94c9-e6e960c6af79","collapsed":false,"execution":{"iopub.status.busy":"2023-05-20T15:41:55.983387Z","iopub.execute_input":"2023-05-20T15:41:55.983925Z","iopub.status.idle":"2023-05-20T15:41:55.997847Z","shell.execute_reply.started":"2023-05-20T15:41:55.983891Z","shell.execute_reply":"2023-05-20T15:41:55.996913Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class DecoderAttention(nn.Module):\n    def __init__(self, params, out_size):\n        super(DecoderAttention, self).__init__()\n        self.hs = params[\"hs\"]\n        self.out_size = out_size\n        self.dp = params[\"dd\"]\n        self.nl = params[\"nl\"]\n        self.bs = params[\"bs\"]\n        self.es = params[\"es\"]\n        self.em = nn.Embedding(out_size, self.es)\n        self.ct = params[\"ct\"]\n    \n        self.attn = nn.Linear(self.hs + self.es, max_inp_len)\n\n        self.attn_combine = nn.Linear(self.hs + self.es, self.hs)\n        \n        self.dpout = nn.Dropout(self.dp)\n        \n        if(self.ct == \"GRU\"):\n            self.gru = nn.GRU(self.hs, self.hs, self.nl, dropout = self.dp)\n            \n        if(self.ct == \"LSTM\"):\n            self.lstm = nn.LSTM(self.hs, self.hs, self.nl, dropout = self.dp)\n            \n        if(self.ct == \"RNN\"):\n            self.rnn = nn.RNN(self.hs, self.hs, self.nl, dropout = self.dp)\n            \n        self.out = nn.Linear(self.hs, self.out_size)\n        \n        self.softmax = nn.LogSoftmax(dim=1)\n\n    def forward(self, input, hidden, enc_outputs):\n        input = input.unsqueeze(0)\n        output = self.dpout(self.em(input).view(-1, self.bs, self.es))\n        \n        if self.ct == \"LSTM\":\n            attn_weights = F.softmax(self.attn(torch.cat((output[0], hidden[0][0]), 1)), dim=1)\n        else:\n            attn_weights = F.softmax(self.attn(torch.cat((output[0], hidden[0]), 1)), dim=1)\n            \n        attn_applied = torch.bmm(attn_weights.unsqueeze(1),enc_outputs.permute(1, 0, 2))\n        attn_applied = attn_applied.squeeze(1)\n        output = torch.cat((output[0], attn_applied), 1)\n        output = self.attn_combine(output).unsqueeze(0)\n        output = F.relu(output)\n        \n        if(self.ct == \"GRU\"):\n            output, hidden = self.gru(output, hidden)\n            \n        if(self.ct == \"LSTM\"):\n            output, (hidden, cell) = self.lstm(output, (hidden[0], hidden[1]))\n            \n        if(self.ct == \"RNN\"):\n            output, hidden = self.rnn(output, hidden)\n            \n        if self.ct == \"LSTM\":\n            return self.out(output[0]), hidden, cell, attn_weights\n        \n        return self.out(output[0]), hidden, attn_weights","metadata":{"_uuid":"cd38fe16-dd06-46ad-a8a1-80a545451ab2","_cell_guid":"d5c23c59-b740-45ee-aece-69b0db7b2409","collapsed":false,"execution":{"iopub.status.busy":"2023-05-20T15:41:56.157489Z","iopub.execute_input":"2023-05-20T15:41:56.158292Z","iopub.status.idle":"2023-05-20T15:41:56.173644Z","shell.execute_reply.started":"2023-05-20T15:41:56.158260Z","shell.execute_reply":"2023-05-20T15:41:56.172641Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Combine:\n    def __init__(self,encoder, decoder, epochs, learning_rate, batch_size, embedding_size, cell_type, train_batch_input, train_batch_target, valid_batch_input,valid_batch_output,hin,nld,nle,dd,de,train_actual_output,hs,bi):\n        self.teacher_forcing_ratio = 0.5\n        self.runEpochs(encoder, decoder, epochs, learning_rate, batch_size, embedding_size, cell_type, train_batch_input, train_batch_target, valid_batch_input,valid_batch_output,hin,nld,nle,dd,de,train_actual_output,hs,bi)\n        \n    def findAccuracy(self, input, actual_output, cell_type, n, batch_size, encoder1, decoder1,hin):\n        correct_output=0\n        no_of_batch=len(input) \n        \n        for i in range(no_of_batch):\n            output_word = self.evaluate(input[i], cell_type, batch_size, encoder1, decoder1,hin)\n            compare_output=actual_output[i]\n            for j in range(len(output_word)):\n                if(output_word[j]==compare_output[j]):\n                    correct_output+=1\n                \n        return correct_output/n*100\n    \n\n    def train(self, train_para): \n        enc_hidden = train_para[\"enc\"].initHidden()\n        train_para[\"optim_enc\"].zero_grad()\n        train_para[\"optim_dec\"].zero_grad()\n\n        input_length = train_para[\"input\"].size(0)\n        target_length = train_para[\"target\"].size(0)\n\n        loss = 0\n        \n        if train_para[\"ct\"] != \"LSTM\":\n            enc_hidden = train_para[\"enc\"](train_para[\"input\"], enc_hidden)\n            \n        else:\n            enc_hidden, enc_cell = train_para[\"enc\"](train_para[\"input\"], enc_hidden)\n\n        dec_input = torch.tensor([SOW_token]*train_para[\"bs\"], device=device)\n\n        dec_hidden = enc_hidden\n        \n        if train_para[\"ct\"] == \"LSTM\":\n            dec_cell = enc_cell\n\n        use_teacher_forcing = True if random.random() < self.teacher_forcing_ratio else False\n\n        if use_teacher_forcing:\n\n            for di in range(target_length):\n                if train_para[\"ct\"] == \"LSTM\":\n                    dec_output, dec_hidden, dec_cell = train_para[\"dec\"](dec_input, (dec_hidden, dec_cell))\n                else:\n                    dec_output, dec_hidden = train_para[\"dec\"](dec_input, dec_hidden)\n                loss += train_para[\"criteria\"](dec_output, train_para[\"target\"][di])\n                dec_input = train_para[\"target\"][di]  # Teacher forcing\n\n        else:\n            for di in range(target_length):\n                if train_para[\"ct\"] == \"LSTM\":\n                    dec_output, dec_hidden, dec_cell = train_para[\"dec\"](dec_input, (dec_hidden, dec_cell))\n                else:\n                    dec_output, dec_hidden = train_para[\"dec\"](dec_input, dec_hidden)\n                _, topi = dec_output.topk(1)\n                dec_input = topi.squeeze().detach()  # detach from history as input\n\n                loss += train_para[\"criteria\"](dec_output, train_para[\"target\"][di])\n\n        loss.backward()\n        train_para[\"optim_enc\"].step()\n        train_para[\"optim_dec\"].step()\n\n        return loss.item() / target_length\n    \n    def runEpochs(self, enc, dec, ep, alpha, bs, es, ct, batch_input, batch_target, valid_batch_input,valid_batch_output,hin,nld,nle,dd,de,train_actual_output,hs,bi):\n        criteria = nn.CrossEntropyLoss()\n        optim_enc = optim.NAdam(enc.parameters(), lr=alpha, weight_decay = 0.0005)\n        optim_dec = optim.NAdam(dec.parameters(), lr=alpha, weight_decay = 0.0005)\n        \n        loss = 0 \n\n        for j in range(ep):\n            print(\"Epoch \", j ,\" started \", datetime.now())\n            for i in range(len(batch_input)):\n                \n                train_para={\"input\":batch_input[i],\n                       \"target\":batch_target[i],\n                       \"enc\":enc,\n                       \"dec\":dec,\n                       \"optim_enc\":optim_enc,\n                       \"optim_dec\":optim_dec,\n                       \"criteria\":criteria,\n                       \"bs\":bs,\n                       \"ct\":ct}\n                l = self.train(train_para)\n                loss = loss+(l*bs)\n\n            loss_avg = loss / len(train_input)\n            loss = 0\n            print(\"Average loss \", j+1, \"epochs is \", loss_avg)\n\n            valid_accuracy = self.findAccuracy(valid_batch_input, valid_batch_output, ct, len(valid_input), bs,enc, dec,hin)\n            print(\"Valid accuracy is \", valid_accuracy)\n            wandb.log({\"validation_accuracy\": valid_accuracy, \"training_loss\": loss_avg, 'epoch': j})\n        train_accuracy = self.findAccuracy(batch_input, train_actual_output, ct,len(batch_input)*bs, bs,enc,dec,hin)\n        print(\"Train accuracy is \", train_accuracy)\n        run_name = \"embS_{}_nlEnc_{}_nlDec_{}_hl_{}_cellType_{}_biDir_{}_dropEnc_{}_dropDec_{}_ep_{}_bs_{}\".format(es, nle, nld, hs, ct, bi, de, dd, ep, bs)\n        wandb.log({\"training_accuracy\": train_accuracy})\n        wandb.run.name = run_name\n        wandb.run.save()\n        wandb.run.finish()\n            \n            \n    def evaluate(self, inp, ct, bs, enc, dec,hin):\n        with torch.no_grad():\n            enc_hidden = enc.initHidden()\n            inp_len = inp.size(0)\n            \n            if ct == \"LSTM\":\n                enc_hidden, enc_cell = enc(inp, enc_hidden)\n            else:\n                enc_hidden = enc(inp, enc_hidden)\n\n            dec_input = torch.tensor([SOW_token]*bs, device=device)  \n            dec_hidden = enc_hidden\n            if ct == \"LSTM\":\n                dec_cell = enc_cell\n                \n            output_words = [\"\"]*bs\n\n            for j in range(inp_len):\n\n                if ct == \"LSTM\":\n                    dec_output, dec_hidden, dec_cell = dec(dec_input, (dec_hidden, dec_cell))\n                else:\n                    dec_output, dec_hidden = dec(dec_input, dec_hidden)\n                _, topi = dec_output.data.topk(1)\n                for i in range(bs):\n                    if topi[i].item() == EOW_token or topi[i] == 0 or topi[i].item()==PAD_token:\n                        continue\n                    else:\n                        output_words[i] += hin.char[topi[i].item()]\n\n                dec_input = topi.squeeze().detach()\n\n            return output_words","metadata":{"_uuid":"9c45c7c3-1b74-4d26-8829-b5dca82c50e0","_cell_guid":"e66555f1-a9f2-4e92-b7a2-f0e293283111","collapsed":false,"execution":{"iopub.status.busy":"2023-05-20T15:41:56.323527Z","iopub.execute_input":"2023-05-20T15:41:56.323821Z","iopub.status.idle":"2023-05-20T15:41:56.353627Z","shell.execute_reply.started":"2023-05-20T15:41:56.323797Z","shell.execute_reply":"2023-05-20T15:41:56.352707Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CombineAttention:\n    def __init__(self,encoder, decoder, epochs, learning_rate, batch_size, embedding_size, cell_type, train_batch_input, train_batch_target, valid_batch_input,valid_batch_output,hin,nld,nle,dd,de,train_actual_output,hs,bi):\n        self.teacher_forcing_ratio = 0.5\n        self.runEpochs(encoder, decoder, epochs, learning_rate, batch_size, embedding_size, cell_type, train_batch_input, train_batch_target, valid_batch_input,valid_batch_output,hin,nld,nle,dd,de,train_actual_output,hs,bi)\n        \n    def findAccuracy(self, input, actual_output, cell_type, n, batch_size, encoder1, decoder1,hin):\n        correct_output=0\n        no_of_batch=len(input) \n        \n        for i in range(no_of_batch):\n            output_word = self.evaluate(input[i], cell_type, batch_size, encoder1, decoder1,hin)\n            compare_output=actual_output[i]\n            for j in range(len(output_word)):\n                if(output_word[j]==compare_output[j]):\n                    correct_output+=1\n                \n        return correct_output/n*100\n    \n\n    def train(self, train_para): \n        enc_hidden = train_para[\"enc\"].initHidden()\n        train_para[\"optim_enc\"].zero_grad()\n        train_para[\"optim_dec\"].zero_grad()\n\n        input_length = train_para[\"input\"].size(0)\n        target_length = train_para[\"target\"].size(0)\n\n        loss = 0\n        \n        if train_para[\"ct\"] != \"LSTM\":\n            enc_output,enc_hidden = train_para[\"enc\"](train_para[\"input\"], enc_hidden)\n            \n        else:\n            enc_output,enc_hidden, enc_cell = train_para[\"enc\"](train_para[\"input\"], enc_hidden)\n\n        dec_input = torch.tensor([SOW_token]*train_para[\"bs\"], device=device)\n\n        dec_hidden = enc_hidden\n        \n        if train_para[\"ct\"] == \"LSTM\":\n            dec_cell = enc_cell\n\n        use_teacher_forcing = True if random.random() < self.teacher_forcing_ratio else False\n\n        if use_teacher_forcing:\n\n            for di in range(target_length):\n                if train_para[\"ct\"] == \"LSTM\":\n                    dec_output, dec_hidden, dec_cell,attn_weights = train_para[\"dec\"](dec_input, (dec_hidden, dec_cell),enc_output)\n                else:\n                    dec_output, dec_hidden,attn_weights = train_para[\"dec\"](dec_input, dec_hidden,enc_output)\n                loss += train_para[\"criteria\"](dec_output, train_para[\"target\"][di])\n                dec_input = train_para[\"target\"][di]\n\n        else:\n            for di in range(target_length):\n                if train_para[\"ct\"] == \"LSTM\":\n                    dec_output, dec_hidden, dec_cell, attn_weights = train_para[\"dec\"](dec_input, (dec_hidden, dec_cell),enc_output)\n                else:\n                    dec_output, dec_hidden,attn_weights = train_para[\"dec\"](dec_input, dec_hidden,enc_output)\n                _, topi = dec_output.topk(1)\n\n                loss += train_para[\"criteria\"](dec_output, train_para[\"target\"][di])\n\n        loss.backward()\n        train_para[\"optim_enc\"].step()\n        train_para[\"optim_dec\"].step()\n\n        return loss.item() / target_length\n    \n    def runEpochs(self, enc, dec, ep, alpha, bs, es, ct, batch_input, batch_target, valid_batch_input,valid_batch_output,hin,nld,nle,dd,de,train_actual_output,hs,bi):\n        criteria = nn.CrossEntropyLoss()\n        optim_enc = optim.NAdam(enc.parameters(), lr=alpha, weight_decay = 0.0005)\n        optim_dec = optim.NAdam(dec.parameters(), lr=alpha, weight_decay = 0.0005)\n        \n        loss = 0 \n\n        for j in range(ep):\n            print(\"Epoch \", j ,\" started \", datetime.now())\n            for i in range(len(batch_input)):\n                \n                train_para={\"input\":batch_input[i],\n                       \"target\":batch_target[i],\n                       \"enc\":enc,\n                       \"dec\":dec,\n                       \"optim_enc\":optim_enc,\n                       \"optim_dec\":optim_dec,\n                       \"criteria\":criteria,\n                       \"bs\":bs,\n                       \"ct\":ct}\n                l = self.train(train_para)\n                loss = loss+(l*bs)\n\n            loss_avg = loss / len(train_input)\n            loss = 0\n            print(\"Average loss \", j+1, \"epochs is \", loss_avg)\n\n            valid_accuracy = self.findAccuracy(valid_batch_input, valid_batch_output, ct, len(valid_input), bs,enc, dec,hin)\n            print(\"Valid accuracy is \", valid_accuracy)\n            wandb.log({\"validation_accuracy\": valid_accuracy, \"training_loss\": loss_avg, 'epoch': j})\n        train_accuracy = self.findAccuracy(batch_input, train_actual_output, ct,len(batch_input)*bs, bs,enc,dec,hin)\n        print(\"Train accuracy is \", train_accuracy)\n        run_name = \"embS_{}_nlEnc_{}_nlDec_{}_hl_{}_cellType_{}_biDir_{}_dropEnc_{}_dropDec_{}_ep_{}_bs_{}\".format(es, nle, nld, hs, ct, bi, de, dd, ep, bs)\n        wandb.log({\"training_accuracy\": train_accuracy})\n        wandb.run.name = run_name\n        wandb.run.save()\n        wandb.run.finish()\n            \n    def evaluate(self, inp, ct, bs, enc, dec,hin):\n        with torch.no_grad():\n            enc_hidden = enc.initHidden()\n            inp_len = inp.size(0)\n            \n            if ct == \"LSTM\":\n                enc_output, enc_hidden, enc_cell = enc(inp, enc_hidden)\n            else:\n                enc_output, enc_hidden = enc(inp, enc_hidden)\n\n            dec_input = torch.tensor([SOW_token]*bs, device=device)  \n            dec_hidden = enc_hidden\n            if ct == \"LSTM\":\n                dec_cell = enc_cell\n                \n            output_words = [\"\"]*bs\n\n            for j in range(inp_len):\n\n                if ct == \"LSTM\":\n                    dec_output, dec_hidden, dec_cell, attn_weights = dec(dec_input, (dec_hidden, dec_cell), enc_output)\n                else:\n                    dec_output, dec_hidden, attn_weights = dec(dec_input, dec_hidden,enc_output)\n                _, topi = dec_output.data.topk(1)\n                for i in range(bs):\n                    if topi[i].item() == EOW_token or topi[i] == 0 or topi[i].item()==PAD_token:\n                        continue\n                    else:\n                        output_words[i] += hin.char[topi[i].item()]\n\n                dec_input = topi.squeeze().detach()\n\n            return output_words","metadata":{"_uuid":"479b2b5d-3a89-473c-b51d-7bfdb909b0cb","_cell_guid":"90fb4051-57a2-434a-80ac-b91df73a40f7","collapsed":false,"execution":{"iopub.status.busy":"2023-05-20T15:41:56.506522Z","iopub.execute_input":"2023-05-20T15:41:56.506804Z","iopub.status.idle":"2023-05-20T15:41:56.536803Z","shell.execute_reply.started":"2023-05-20T15:41:56.506780Z","shell.execute_reply":"2023-05-20T15:41:56.535861Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"max_inp_len,max_out_len=loadData()","metadata":{"_uuid":"8fc5c986-af52-4f11-8386-f864ef14fb4e","_cell_guid":"e851e81b-d528-4b42-b574-fd74410abc48","collapsed":false,"execution":{"iopub.status.busy":"2023-05-20T15:41:56.860439Z","iopub.execute_input":"2023-05-20T15:41:56.860917Z","iopub.status.idle":"2023-05-20T15:41:57.008829Z","shell.execute_reply.started":"2023-05-20T15:41:56.860887Z","shell.execute_reply":"2023-05-20T15:41:57.007711Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def runSweep():\n    \n    config_defaults = {\n        \"es\": 64,\n        \"nle\": 3,\n        \"nld\": 3,\n        \"hs\": 256,\n        \"ct\": \"LSTM\",\n        \"bi\": True,\n        \"de\": 0.2,\n        \"dd\": 0.3,\n        \"ep\": 20,\n        \"bs\": 128,\n        \"attention\":False,\n        }\n    \n    wandb.init(project = 'Assignment3', entity = 'cs22m020', config=config_defaults)\n    es = wandb.config.es\n    nle = wandb.config.nl\n    nld = wandb.config.nl\n    hs = wandb.config.hs\n    bs = wandb.config.bs\n    ep = wandb.config.ep\n    ct = wandb.config.ct\n    bi = wandb.config.bi\n    de = wandb.config.de\n    dd = wandb.config.dd\n    attention=wandb.config.attention\n    \n    alpha = 0.001\n    \n    params={\"hs\":hs,\n            \"nl\":nle,\n            \"de\":de,\n            \"dd\":dd,\n            \"bs\":bs,\n            \"es\": es,\n            \"ep\":ep,\n            \"ct\":ct,\n            \"alpha\":alpha,\n            \"bi\":bi,\n            \"attention\":attention\n            }\n    \n    eng=Dictionary(max_inp_len)\n    hin=Dictionary(max_out_len)\n    train_batch_input=eng.driver(train_input,params[\"bs\"])\n    train_batch_target=hin.driver(train_output,params[\"bs\"])\n    valid_batch_input=eng.driver(valid_input,params[\"bs\"])\n    valid_batch_output=[]\n\n    #go over the validation output and convert to batches\n    for i in range(0,len(valid_output),params[\"bs\"]):\n        if i+params[\"bs\"]>=len(valid_output):\n            break\n        temp=[]\n        for j in range(i,i+params[\"bs\"]):\n            temp.append(valid_output[j])\n        valid_batch_output.append(temp)\n\n\n    train_actual_output=[]\n    for i in range(0,len(train_output),params[\"bs\"]):\n        if i+params[\"bs\"]>=len(train_output):\n            break\n        temp=[]\n        for j in range(i,i+params[\"bs\"]):\n            temp.append(train_output[j])\n        train_actual_output.append(temp)\n    \n    \n    if attention==False:\n        encoder1 = Encoder(eng.n_chars, params).to(device)\n        decoder1 = Decoder(params, hin.n_chars).to(device)\n        Combine(encoder1, decoder1, ep, alpha, bs, es, ct, train_batch_input, train_batch_target, valid_batch_input,valid_batch_output,hin, nld,nle,dd,de,train_actual_output,hs,bi)\n    else:\n        encoder1 = EncoderAttention(eng.n_chars, params).to(device)\n        decoder1 = DecoderAttention(params, hin.n_chars).to(device)\n        CombineAttention(encoder1, decoder1, ep, alpha, bs, es, ct, train_batch_input, train_batch_target, valid_batch_input,valid_batch_output,hin, nld,nle,dd,de,train_actual_output,hs,bi)","metadata":{"_uuid":"7be97bfa-7136-47fd-8393-43c8bdd892fe","_cell_guid":"7433d379-ae4e-4e4b-92b2-35c799bbf62a","collapsed":false,"execution":{"iopub.status.busy":"2023-05-20T15:43:58.551596Z","iopub.execute_input":"2023-05-20T15:43:58.551963Z","iopub.status.idle":"2023-05-20T15:43:58.579609Z","shell.execute_reply.started":"2023-05-20T15:43:58.551932Z","shell.execute_reply":"2023-05-20T15:43:58.577917Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sweep_config = {\n  \"name\": \"Recurrent Neural Network - Cross Entropy Loss\",\n  \"metric\": {\n      \"name\":\"validation_accuracy\",\n      \"goal\": \"maximize\"\n  },\n  \"method\": \"bayes\",\n  \"parameters\": {\n        \"es\": {\n            \"values\": [512, 256, 64, 32]\n        },\n        \"nl\": {\n            \"values\": [3, 2, 1]\n        },\n        \"hs\": {\n            \"values\": [512, 256, 128]\n        },\n        \"ct\": {\n            \"values\": [\"RNN\", \"GRU\", \"LSTM\"]\n        },\n        \"bi\": {\n            \"values\": [False, True]\n        },\n        \"de\": {\n            \"values\": [0.2, 0.3, 0.4]\n        },\n        \"dd\": {\n            \"values\": [0.2, 0.3, 0.4]\n        },\n        \"ep\": {\n            \"values\": [2, 3]\n        },\n        \"bs\": {\n            \"values\": [256, 128, 64, 32]\n        },\n        \"attention\": {\n            \"values\": [False,True]\n        }\n    }\n}\nsweep_id = wandb.sweep(sweep_config, entity=\"cs22m020\", project=\"Assignment3\")\nwandb.agent(sweep_id, runSweep, count = 2)","metadata":{"_uuid":"c8f1a5e4-ba57-4078-b09a-a68a00fb7de1","_cell_guid":"49c43f5b-89c1-47a9-8d93-113e063a56d7","collapsed":false,"execution":{"iopub.status.busy":"2023-05-20T15:44:01.436573Z","iopub.execute_input":"2023-05-20T15:44:01.436928Z","iopub.status.idle":"2023-05-20T15:53:16.350705Z","shell.execute_reply.started":"2023-05-20T15:44:01.436897Z","shell.execute_reply":"2023-05-20T15:53:16.349621Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"_uuid":"2a96b35d-582c-4ba5-9c1b-8c50cdd24583","_cell_guid":"1efccbc6-da0c-46e4-b996-69e79a43614e","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]}]}